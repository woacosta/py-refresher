{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "examples from https://cognitus.fr/mllib-p2-feature-transformation/"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "# May take a little while on a local computer\nspark = SparkSession.builder.appName(\"hockey\").getOrCreate()"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": "file_loc = 'gs://wac-buck/colors.csv'"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "df = spark.read.format('csv').option('inferSchema',\n                                    True).option('header',True).load(file_loc)"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[id: int, color: string]"}, "metadata": {}, "output_type": "display_data"}], "source": "display(df)"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+------+\n| id| color|\n+---+------+\n|  1|   red|\n|  2|  blue|\n|  3|orange|\n|  4| white|\n|  5|   red|\n|  6|orange|\n|  7|   red|\n|  8| white|\n|  9|   red|\n+---+------+\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": "['id', 'color']"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "df.columns"}, {"cell_type": "markdown", "metadata": {}, "source": "# StringIndexer"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import StringIndexer\nindexer = StringIndexer(inputCol=\"color\", outputCol=\"color_indexed\")"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": "indexer_model = indexer.fit(df)"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": "indexed_data= indexer_model.transform(df)"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+------+-------------+\n| id| color|color_indexed|\n+---+------+-------------+\n|  1|   red|          0.0|\n|  2|  blue|          3.0|\n|  3|orange|          2.0|\n|  4| white|          1.0|\n|  5|   red|          0.0|\n|  6|orange|          2.0|\n|  7|   red|          0.0|\n|  8| white|          1.0|\n|  9|   red|          0.0|\n+---+------+-------------+\n\n"}], "source": "indexed_data.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "# OneHotEncoderEstimator\nnote that color is a nominal var meaning the order doesn't matter. This is why it's best to create dummies so that the model does not infer more significance to larger values."}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import OneHotEncoderEstimator\nohe = OneHotEncoderEstimator(inputCols=[\"color_indexed\"], outputCols=[\"color_ohe\"])"}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": "ohe_model = ohe.fit(indexed_data)\n"}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+------+-------------+-------------+\n| id| color|color_indexed|    color_ohe|\n+---+------+-------------+-------------+\n|  1|   red|          0.0|(3,[0],[1.0])|\n|  2|  blue|          3.0|    (3,[],[])|\n|  3|orange|          2.0|(3,[2],[1.0])|\n|  4| white|          1.0|(3,[1],[1.0])|\n|  5|   red|          0.0|(3,[0],[1.0])|\n|  6|orange|          2.0|(3,[2],[1.0])|\n|  7|   red|          0.0|(3,[0],[1.0])|\n|  8| white|          1.0|(3,[1],[1.0])|\n|  9|   red|          0.0|(3,[0],[1.0])|\n+---+------+-------------+-------------+\n\n"}], "source": "encoded_data = ohe_model.transform(indexed_data)\nencoded_data.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "# Scaling and normalizing"}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": "file_loc = 'gs://wac-buck/wine.data'\ndf = spark.read.csv(file_loc,header=False,\n                    inferSchema=True)"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\n|  1|14.23|1.71|2.43|15.6|127| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065|\n|  1| 13.2|1.78|2.14|11.2|100|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050|\n|  1|13.16|2.36|2.67|18.6|101| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185|\n|  1|14.37|1.95| 2.5|16.8|113|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480|\n|  1|13.24|2.59|2.87|21.0|118| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735|\n|  1| 14.2|1.76|2.45|15.2|112|3.27|3.39|0.34|1.97|6.75|1.05|2.85|1450|\n|  1|14.39|1.87|2.45|14.6| 96| 2.5|2.52| 0.3|1.98|5.25|1.02|3.58|1290|\n|  1|14.06|2.15|2.61|17.6|121| 2.6|2.51|0.31|1.25|5.05|1.06|3.58|1295|\n|  1|14.83|1.64|2.17|14.0| 97| 2.8|2.98|0.29|1.98| 5.2|1.08|2.85|1045|\n|  1|13.86|1.35|2.27|16.0| 98|2.98|3.15|0.22|1.85|7.22|1.01|3.55|1045|\n|  1| 14.1|2.16| 2.3|18.0|105|2.95|3.32|0.22|2.38|5.75|1.25|3.17|1510|\n|  1|14.12|1.48|2.32|16.8| 95| 2.2|2.43|0.26|1.57| 5.0|1.17|2.82|1280|\n|  1|13.75|1.73|2.41|16.0| 89| 2.6|2.76|0.29|1.81| 5.6|1.15| 2.9|1320|\n|  1|14.75|1.73|2.39|11.4| 91| 3.1|3.69|0.43|2.81| 5.4|1.25|2.73|1150|\n|  1|14.38|1.87|2.38|12.0|102| 3.3|3.64|0.29|2.96| 7.5| 1.2| 3.0|1547|\n|  1|13.63|1.81| 2.7|17.2|112|2.85|2.91| 0.3|1.46| 7.3|1.28|2.88|1310|\n|  1| 14.3|1.92|2.72|20.0|120| 2.8|3.14|0.33|1.97| 6.2|1.07|2.65|1280|\n|  1|13.83|1.57|2.62|20.0|115|2.95| 3.4| 0.4|1.72| 6.6|1.13|2.57|1130|\n|  1|14.19|1.59|2.48|16.5|108| 3.3|3.93|0.32|1.86| 8.7|1.23|2.82|1680|\n|  1|13.64| 3.1|2.56|15.2|116| 2.7|3.03|0.17|1.66| 5.1|0.96|3.36| 845|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+\nonly showing top 20 rows\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------------------+------------------+-----------------+-------------------+------------------+-----------------+\n|summary|               _c0|               _c1|               _c2|               _c3|              _c4|               _c5|               _c6|               _c7|                _c8|               _c9|             _c10|               _c11|              _c12|             _c13|\n+-------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------------------+------------------+-----------------+-------------------+------------------+-----------------+\n|  count|               178|               178|               178|               178|              178|               178|               178|               178|                178|               178|              178|                178|               178|              178|\n|   mean|1.9382022471910112|13.000617977528083| 2.336348314606741|2.3665168539325854|19.49494382022472| 99.74157303370787| 2.295112359550562|2.0292696629213474|0.36185393258426973|1.5908988764044953|5.058089882022473| 0.9574494382022468|2.6116853932584254|746.8932584269663|\n| stddev|0.7750349899850563| 0.811826538005858|1.1171460976144625|0.2743440090608148|3.339563767173504|14.282483515295652|0.6258510488339892|0.9988586850169471|0.12445334029667941|0.5723588626747612|2.318285871822413|0.22857156582982324|0.7099904287650503|314.9074742768492|\n|    min|                 1|             11.03|              0.74|              1.36|             10.6|                70|              0.98|              0.34|               0.13|              0.41|             1.28|               0.48|              1.27|              278|\n|    max|                 3|             14.83|               5.8|              3.23|             30.0|               162|              3.88|              5.08|               0.66|              3.58|             13.0|               1.71|               4.0|             1680|\n+-------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------------------+------------------+-----------------+-------------------+------------------+-----------------+\n\n"}], "source": "df.describe().show()"}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=df.columns[1:], outputCol=\"features\")\ndata_2 = assembler.transform(df)"}, {"cell_type": "code", "execution_count": 29, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+\n|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|            features|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+\n|  1|14.23|1.71|2.43|15.6|127| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065|[14.23,1.71,2.43,...|\n|  1| 13.2|1.78|2.14|11.2|100|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050|[13.2,1.78,2.14,1...|\n|  1|13.16|2.36|2.67|18.6|101| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185|[13.16,2.36,2.67,...|\n|  1|14.37|1.95| 2.5|16.8|113|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480|[14.37,1.95,2.5,1...|\n|  1|13.24|2.59|2.87|21.0|118| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735|[13.24,2.59,2.87,...|\n|  1| 14.2|1.76|2.45|15.2|112|3.27|3.39|0.34|1.97|6.75|1.05|2.85|1450|[14.2,1.76,2.45,1...|\n|  1|14.39|1.87|2.45|14.6| 96| 2.5|2.52| 0.3|1.98|5.25|1.02|3.58|1290|[14.39,1.87,2.45,...|\n|  1|14.06|2.15|2.61|17.6|121| 2.6|2.51|0.31|1.25|5.05|1.06|3.58|1295|[14.06,2.15,2.61,...|\n|  1|14.83|1.64|2.17|14.0| 97| 2.8|2.98|0.29|1.98| 5.2|1.08|2.85|1045|[14.83,1.64,2.17,...|\n|  1|13.86|1.35|2.27|16.0| 98|2.98|3.15|0.22|1.85|7.22|1.01|3.55|1045|[13.86,1.35,2.27,...|\n|  1| 14.1|2.16| 2.3|18.0|105|2.95|3.32|0.22|2.38|5.75|1.25|3.17|1510|[14.1,2.16,2.3,18...|\n|  1|14.12|1.48|2.32|16.8| 95| 2.2|2.43|0.26|1.57| 5.0|1.17|2.82|1280|[14.12,1.48,2.32,...|\n|  1|13.75|1.73|2.41|16.0| 89| 2.6|2.76|0.29|1.81| 5.6|1.15| 2.9|1320|[13.75,1.73,2.41,...|\n|  1|14.75|1.73|2.39|11.4| 91| 3.1|3.69|0.43|2.81| 5.4|1.25|2.73|1150|[14.75,1.73,2.39,...|\n|  1|14.38|1.87|2.38|12.0|102| 3.3|3.64|0.29|2.96| 7.5| 1.2| 3.0|1547|[14.38,1.87,2.38,...|\n|  1|13.63|1.81| 2.7|17.2|112|2.85|2.91| 0.3|1.46| 7.3|1.28|2.88|1310|[13.63,1.81,2.7,1...|\n|  1| 14.3|1.92|2.72|20.0|120| 2.8|3.14|0.33|1.97| 6.2|1.07|2.65|1280|[14.3,1.92,2.72,2...|\n|  1|13.83|1.57|2.62|20.0|115|2.95| 3.4| 0.4|1.72| 6.6|1.13|2.57|1130|[13.83,1.57,2.62,...|\n|  1|14.19|1.59|2.48|16.5|108| 3.3|3.93|0.32|1.86| 8.7|1.23|2.82|1680|[14.19,1.59,2.48,...|\n|  1|13.64| 3.1|2.56|15.2|116| 2.7|3.03|0.17|1.66| 5.1|0.96|3.36| 845|[13.64,3.1,2.56,1...|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+\nonly showing top 20 rows\n\n"}], "source": "data_2.show()"}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import StandardScaler\nscaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")"}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [], "source": "scaler_model = scaler.fit(data_2)"}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [], "source": "scaled_data = scaler_model.transform(data_2)"}, {"cell_type": "code", "execution_count": 33, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+--------------------+\n|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|            features|     scaled_features|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+--------------------+\n|  1|14.23|1.71|2.43|15.6|127| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065|[14.23,1.71,2.43,...|[17.5283750084766...|\n|  1| 13.2|1.78|2.14|11.2|100|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050|[13.2,1.78,2.14,1...|[16.2596310690015...|\n|  1|13.16|2.36|2.67|18.6|101| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185|[13.16,2.36,2.67,...|[16.2103594597015...|\n|  1|14.37|1.95| 2.5|16.8|113|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480|[14.37,1.95,2.5,1...|[17.7008256410266...|\n|  1|13.24|2.59|2.87|21.0|118| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735|[13.24,2.59,2.87,...|[16.3089026783015...|\n|  1| 14.2|1.76|2.45|15.2|112|3.27|3.39|0.34|1.97|6.75|1.05|2.85|1450|[14.2,1.76,2.45,1...|[17.4914213015016...|\n|  1|14.39|1.87|2.45|14.6| 96| 2.5|2.52| 0.3|1.98|5.25|1.02|3.58|1290|[14.39,1.87,2.45,...|[17.7254614456766...|\n|  1|14.06|2.15|2.61|17.6|121| 2.6|2.51|0.31|1.25|5.05|1.06|3.58|1295|[14.06,2.15,2.61,...|[17.3189706689516...|\n|  1|14.83|1.64|2.17|14.0| 97| 2.8|2.98|0.29|1.98| 5.2|1.08|2.85|1045|[14.83,1.64,2.17,...|[18.2674491479767...|\n|  1|13.86|1.35|2.27|16.0| 98|2.98|3.15|0.22|1.85|7.22|1.01|3.55|1045|[13.86,1.35,2.27,...|[17.0726126224516...|\n|  1| 14.1|2.16| 2.3|18.0|105|2.95|3.32|0.22|2.38|5.75|1.25|3.17|1510|[14.1,2.16,2.3,18...|[17.3682422782516...|\n|  1|14.12|1.48|2.32|16.8| 95| 2.2|2.43|0.26|1.57| 5.0|1.17|2.82|1280|[14.12,1.48,2.32,...|[17.3928780829016...|\n|  1|13.75|1.73|2.41|16.0| 89| 2.6|2.76|0.29|1.81| 5.6|1.15| 2.9|1320|[13.75,1.73,2.41,...|[16.9371156968765...|\n|  1|14.75|1.73|2.39|11.4| 91| 3.1|3.69|0.43|2.81| 5.4|1.25|2.73|1150|[14.75,1.73,2.39,...|[18.1689059293767...|\n|  1|14.38|1.87|2.38|12.0|102| 3.3|3.64|0.29|2.96| 7.5| 1.2| 3.0|1547|[14.38,1.87,2.38,...|[17.7131435433516...|\n|  1|13.63|1.81| 2.7|17.2|112|2.85|2.91| 0.3|1.46| 7.3|1.28|2.88|1310|[13.63,1.81,2.7,1...|[16.7893008689765...|\n|  1| 14.3|1.92|2.72|20.0|120| 2.8|3.14|0.33|1.97| 6.2|1.07|2.65|1280|[14.3,1.92,2.72,2...|[17.6146003247516...|\n|  1|13.83|1.57|2.62|20.0|115|2.95| 3.4| 0.4|1.72| 6.6|1.13|2.57|1130|[13.83,1.57,2.62,...|[17.0356589154766...|\n|  1|14.19|1.59|2.48|16.5|108| 3.3|3.93|0.32|1.86| 8.7|1.23|2.82|1680|[14.19,1.59,2.48,...|[17.4791033991766...|\n|  1|13.64| 3.1|2.56|15.2|116| 2.7|3.03|0.17|1.66| 5.1|0.96|3.36| 845|[13.64,3.1,2.56,1...|[16.8016187713015...|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+--------------------+\nonly showing top 20 rows\n\n"}], "source": "scaled_data.show()"}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import MinMaxScaler\nscaler = MinMaxScaler(min=0, max=1, inputCol='features', outputCol='features_minmax')\nscaler_model = scaler.fit(data_2)\ndata_3 = scaler_model.transform(data_2)"}, {"cell_type": "code", "execution_count": 35, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+--------------------+\n|_c0|  _c1| _c2| _c3| _c4|_c5| _c6| _c7| _c8| _c9|_c10|_c11|_c12|_c13|            features|     features_minmax|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+--------------------+\n|  1|14.23|1.71|2.43|15.6|127| 2.8|3.06|0.28|2.29|5.64|1.04|3.92|1065|[14.23,1.71,2.43,...|[0.84210526315789...|\n|  1| 13.2|1.78|2.14|11.2|100|2.65|2.76|0.26|1.28|4.38|1.05| 3.4|1050|[13.2,1.78,2.14,1...|[0.57105263157894...|\n|  1|13.16|2.36|2.67|18.6|101| 2.8|3.24| 0.3|2.81|5.68|1.03|3.17|1185|[13.16,2.36,2.67,...|[0.56052631578947...|\n|  1|14.37|1.95| 2.5|16.8|113|3.85|3.49|0.24|2.18| 7.8|0.86|3.45|1480|[14.37,1.95,2.5,1...|[0.87894736842105...|\n|  1|13.24|2.59|2.87|21.0|118| 2.8|2.69|0.39|1.82|4.32|1.04|2.93| 735|[13.24,2.59,2.87,...|[0.58157894736842...|\n|  1| 14.2|1.76|2.45|15.2|112|3.27|3.39|0.34|1.97|6.75|1.05|2.85|1450|[14.2,1.76,2.45,1...|[0.83421052631578...|\n|  1|14.39|1.87|2.45|14.6| 96| 2.5|2.52| 0.3|1.98|5.25|1.02|3.58|1290|[14.39,1.87,2.45,...|[0.88421052631578...|\n|  1|14.06|2.15|2.61|17.6|121| 2.6|2.51|0.31|1.25|5.05|1.06|3.58|1295|[14.06,2.15,2.61,...|[0.79736842105263...|\n|  1|14.83|1.64|2.17|14.0| 97| 2.8|2.98|0.29|1.98| 5.2|1.08|2.85|1045|[14.83,1.64,2.17,...|[1.0,0.1778656126...|\n|  1|13.86|1.35|2.27|16.0| 98|2.98|3.15|0.22|1.85|7.22|1.01|3.55|1045|[13.86,1.35,2.27,...|[0.74473684210526...|\n|  1| 14.1|2.16| 2.3|18.0|105|2.95|3.32|0.22|2.38|5.75|1.25|3.17|1510|[14.1,2.16,2.3,18...|[0.80789473684210...|\n|  1|14.12|1.48|2.32|16.8| 95| 2.2|2.43|0.26|1.57| 5.0|1.17|2.82|1280|[14.12,1.48,2.32,...|[0.81315789473684...|\n|  1|13.75|1.73|2.41|16.0| 89| 2.6|2.76|0.29|1.81| 5.6|1.15| 2.9|1320|[13.75,1.73,2.41,...|[0.71578947368421...|\n|  1|14.75|1.73|2.39|11.4| 91| 3.1|3.69|0.43|2.81| 5.4|1.25|2.73|1150|[14.75,1.73,2.39,...|[0.97894736842105...|\n|  1|14.38|1.87|2.38|12.0|102| 3.3|3.64|0.29|2.96| 7.5| 1.2| 3.0|1547|[14.38,1.87,2.38,...|[0.88157894736842...|\n|  1|13.63|1.81| 2.7|17.2|112|2.85|2.91| 0.3|1.46| 7.3|1.28|2.88|1310|[13.63,1.81,2.7,1...|[0.68421052631578...|\n|  1| 14.3|1.92|2.72|20.0|120| 2.8|3.14|0.33|1.97| 6.2|1.07|2.65|1280|[14.3,1.92,2.72,2...|[0.86052631578947...|\n|  1|13.83|1.57|2.62|20.0|115|2.95| 3.4| 0.4|1.72| 6.6|1.13|2.57|1130|[13.83,1.57,2.62,...|[0.73684210526315...|\n|  1|14.19|1.59|2.48|16.5|108| 3.3|3.93|0.32|1.86| 8.7|1.23|2.82|1680|[14.19,1.59,2.48,...|[0.83157894736842...|\n|  1|13.64| 3.1|2.56|15.2|116| 2.7|3.03|0.17|1.66| 5.1|0.96|3.36| 845|[13.64,3.1,2.56,1...|[0.68684210526315...|\n+---+-----+----+----+----+---+----+----+----+----+----+----+----+----+--------------------+--------------------+\nonly showing top 20 rows\n\n"}], "source": "data_3.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "# Principal component analysis/dimension reduction"}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [], "source": "file_loc = 'gs://wac-buck/digits.csv'\ndf = spark.read.csv(file_loc,header=True,\n                    inferSchema=True)"}, {"cell_type": "code", "execution_count": 39, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=df.columns[1:], outputCol='features')\ndata_2 = assembler.transform(df)"}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import PCA\nfrom pyspark.ml.linalg import Vectors"}, {"cell_type": "code", "execution_count": 42, "metadata": {}, "outputs": [], "source": "pca = PCA(k=2, inputCol='features', outputCol='features_pca')"}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [], "source": "pca_model = pca.fit(data_2)"}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [], "source": "pca_data = pca_model.transform(data_2).select('features_pca')"}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|        features_pca|\n+--------------------+\n|[103.738813757988...|\n|[2466.78627830941...|\n|[-121.55984060477...|\n|[599.578991071954...|\n|[2689.04430947599...|\n|[1253.08650413365...|\n|[93.0114290617972...|\n|[650.952778816166...|\n|[1115.56395904828...|\n|[1062.72668192117...|\n|[1029.01690081557...|\n|[458.805321389773...|\n|[-200.34133976161...|\n|[751.263926957190...|\n|[1265.44211418056...|\n|[-199.11010313255...|\n|[762.715694923051...|\n|[1744.79986516160...|\n|[128.314928856545...|\n|[1731.44148649030...|\n+--------------------+\nonly showing top 20 rows\n\n"}], "source": "pca_data.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "# Titanic classification example"}, {"cell_type": "code", "execution_count": 46, "metadata": {}, "outputs": [], "source": "file_loc = 'gs://wac-buck/titanic.csv'\ndf = spark.read.csv(file_loc,header=True,\n                    inferSchema=True)"}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n"}], "source": "df.show()"}, {"cell_type": "code", "execution_count": 48, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- PassengerId: integer (nullable = true)\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- SibSp: integer (nullable = true)\n |-- Parch: integer (nullable = true)\n |-- Ticket: string (nullable = true)\n |-- Fare: double (nullable = true)\n |-- Cabin: string (nullable = true)\n |-- Embarked: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": 49, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n|summary|      PassengerId|           Survived|            Pclass|                Name|Gender|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n\n"}], "source": "df.describe().show()"}, {"cell_type": "markdown", "metadata": {}, "source": "* It does not make sense to include some features such as: PassengerID, Name and Ticket \u2192 we will drop them\n* Cabin has a lot of null values \u2192 we will drop it as well\n* Maybe the Embarked column has nothing to do with the survival \u2192 let us remove it\n* We are missing 177 values from the Age column \u2192 Age is important, we need to find a way to deal with the missing values\n* Gender has nominal values \u2192 need to encode them"}, {"cell_type": "code", "execution_count": 51, "metadata": {}, "outputs": [], "source": "data = df.select(['Survived', 'Pclass', 'Gender', 'Age', 'SibSp', 'Parch', 'Fare'])"}, {"cell_type": "markdown", "metadata": {}, "source": "# Impute values - change nulls to means"}, {"cell_type": "markdown", "metadata": {}, "source": "There are many available strategies, but we will follow a simple one that fills missing values with the mean value calculated from the sample.\n\nMLlib makes the job easy using the Imputer class. First, we define the estimator, fit it to the model, then we apply the transformer on the data"}, {"cell_type": "code", "execution_count": 52, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import Imputer\nimputer = Imputer(strategy='mean', inputCols=['Age'], outputCols=['AgeImputed'])\nimputer_model = imputer.fit(data)\ndata = imputer_model.transform(data)"}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+------+------+----+-----+-----+-------+-----------------+\n|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       AgeImputed|\n+--------+------+------+----+-----+-----+-------+-----------------+\n|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|\n|       1|     1|female|38.0|    1|    0|71.2833|             38.0|\n|       1|     3|female|26.0|    0|    0|  7.925|             26.0|\n|       1|     1|female|35.0|    1|    0|   53.1|             35.0|\n|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|\n|       0|     3|  male|null|    0|    0| 8.4583|29.69911764705882|\n|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|\n|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|\n|       1|     3|female|27.0|    0|    2|11.1333|             27.0|\n|       1|     2|female|14.0|    1|    0|30.0708|             14.0|\n|       1|     3|female| 4.0|    1|    1|   16.7|              4.0|\n|       1|     1|female|58.0|    0|    0|  26.55|             58.0|\n|       0|     3|  male|20.0|    0|    0|   8.05|             20.0|\n|       0|     3|  male|39.0|    1|    5| 31.275|             39.0|\n|       0|     3|female|14.0|    0|    0| 7.8542|             14.0|\n|       1|     2|female|55.0|    0|    0|   16.0|             55.0|\n|       0|     3|  male| 2.0|    4|    1| 29.125|              2.0|\n|       1|     2|  male|null|    0|    0|   13.0|29.69911764705882|\n|       0|     3|female|31.0|    1|    0|   18.0|             31.0|\n|       1|     3|female|null|    0|    0|  7.225|29.69911764705882|\n+--------+------+------+----+-----+-----+-------+-----------------+\nonly showing top 20 rows\n\n"}], "source": "data.show()"}, {"cell_type": "code", "execution_count": 54, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import StringIndexer\ngender_indexer = StringIndexer(inputCol='Gender', outputCol='GenderIndexed')\ngender_indexer_model = gender_indexer.fit(data)\ndata = gender_indexer_model.transform(data)"}, {"cell_type": "code", "execution_count": 55, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       AgeImputed|GenderIndexed|\n+--------+------+------+----+-----+-----+-------+-----------------+-------------+\n|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|          0.0|\n|       1|     1|female|38.0|    1|    0|71.2833|             38.0|          1.0|\n|       1|     3|female|26.0|    0|    0|  7.925|             26.0|          1.0|\n|       1|     1|female|35.0|    1|    0|   53.1|             35.0|          1.0|\n|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|          0.0|\n|       0|     3|  male|null|    0|    0| 8.4583|29.69911764705882|          0.0|\n|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|          0.0|\n|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|          0.0|\n|       1|     3|female|27.0|    0|    2|11.1333|             27.0|          1.0|\n|       1|     2|female|14.0|    1|    0|30.0708|             14.0|          1.0|\n|       1|     3|female| 4.0|    1|    1|   16.7|              4.0|          1.0|\n|       1|     1|female|58.0|    0|    0|  26.55|             58.0|          1.0|\n|       0|     3|  male|20.0|    0|    0|   8.05|             20.0|          0.0|\n|       0|     3|  male|39.0|    1|    5| 31.275|             39.0|          0.0|\n|       0|     3|female|14.0|    0|    0| 7.8542|             14.0|          1.0|\n|       1|     2|female|55.0|    0|    0|   16.0|             55.0|          1.0|\n|       0|     3|  male| 2.0|    4|    1| 29.125|              2.0|          0.0|\n|       1|     2|  male|null|    0|    0|   13.0|29.69911764705882|          0.0|\n|       0|     3|female|31.0|    1|    0|   18.0|             31.0|          1.0|\n|       1|     3|female|null|    0|    0|  7.225|29.69911764705882|          1.0|\n+--------+------+------+----+-----+-----+-------+-----------------+-------------+\nonly showing top 20 rows\n\n"}], "source": "data.show()"}, {"cell_type": "code", "execution_count": 56, "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(inputCols=['Pclass', 'SibSp', 'Parch', 'Fare', 'AgeImputed', 'GenderIndexed'], outputCol='features')\ndata = assembler.transform(data)"}, {"cell_type": "code", "execution_count": 57, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+------+------+----+-----+-----+-------+-----------------+-------------+--------------------+\n|Survived|Pclass|Gender| Age|SibSp|Parch|   Fare|       AgeImputed|GenderIndexed|            features|\n+--------+------+------+----+-----+-----+-------+-----------------+-------------+--------------------+\n|       0|     3|  male|22.0|    1|    0|   7.25|             22.0|          0.0|[3.0,1.0,0.0,7.25...|\n|       1|     1|female|38.0|    1|    0|71.2833|             38.0|          1.0|[1.0,1.0,0.0,71.2...|\n|       1|     3|female|26.0|    0|    0|  7.925|             26.0|          1.0|[3.0,0.0,0.0,7.92...|\n|       1|     1|female|35.0|    1|    0|   53.1|             35.0|          1.0|[1.0,1.0,0.0,53.1...|\n|       0|     3|  male|35.0|    0|    0|   8.05|             35.0|          0.0|[3.0,0.0,0.0,8.05...|\n|       0|     3|  male|null|    0|    0| 8.4583|29.69911764705882|          0.0|[3.0,0.0,0.0,8.45...|\n|       0|     1|  male|54.0|    0|    0|51.8625|             54.0|          0.0|[1.0,0.0,0.0,51.8...|\n|       0|     3|  male| 2.0|    3|    1| 21.075|              2.0|          0.0|[3.0,3.0,1.0,21.0...|\n|       1|     3|female|27.0|    0|    2|11.1333|             27.0|          1.0|[3.0,0.0,2.0,11.1...|\n|       1|     2|female|14.0|    1|    0|30.0708|             14.0|          1.0|[2.0,1.0,0.0,30.0...|\n|       1|     3|female| 4.0|    1|    1|   16.7|              4.0|          1.0|[3.0,1.0,1.0,16.7...|\n|       1|     1|female|58.0|    0|    0|  26.55|             58.0|          1.0|[1.0,0.0,0.0,26.5...|\n|       0|     3|  male|20.0|    0|    0|   8.05|             20.0|          0.0|[3.0,0.0,0.0,8.05...|\n|       0|     3|  male|39.0|    1|    5| 31.275|             39.0|          0.0|[3.0,1.0,5.0,31.2...|\n|       0|     3|female|14.0|    0|    0| 7.8542|             14.0|          1.0|[3.0,0.0,0.0,7.85...|\n|       1|     2|female|55.0|    0|    0|   16.0|             55.0|          1.0|[2.0,0.0,0.0,16.0...|\n|       0|     3|  male| 2.0|    4|    1| 29.125|              2.0|          0.0|[3.0,4.0,1.0,29.1...|\n|       1|     2|  male|null|    0|    0|   13.0|29.69911764705882|          0.0|[2.0,0.0,0.0,13.0...|\n|       0|     3|female|31.0|    1|    0|   18.0|             31.0|          1.0|[3.0,1.0,0.0,18.0...|\n|       1|     3|female|null|    0|    0|  7.225|29.69911764705882|          1.0|[3.0,0.0,0.0,7.22...|\n+--------+------+------+----+-----+-----+-------+-----------------+-------------+--------------------+\nonly showing top 20 rows\n\n"}], "source": "data.show()"}, {"cell_type": "code", "execution_count": 58, "metadata": {}, "outputs": [], "source": "from pyspark.ml.classification import RandomForestClassifier\nalgo = RandomForestClassifier(featuresCol='features', labelCol='Survived')\nmodel = algo.fit(data)"}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [], "source": "predictions = model.transform(data)"}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [], "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\nevaluator = BinaryClassificationEvaluator(labelCol='Survived', metricName='areaUnderROC')"}, {"cell_type": "code", "execution_count": 61, "metadata": {}, "outputs": [{"data": {"text/plain": "0.8998737736874062"}, "execution_count": 61, "metadata": {}, "output_type": "execute_result"}], "source": "evaluator.evaluate(predictions)"}, {"cell_type": "code", "execution_count": 62, "metadata": {}, "outputs": [], "source": "y_true = predictions.select(['Survived']).collect()\ny_pred = predictions.select(['prediction']).collect()"}, {"cell_type": "code", "execution_count": 63, "metadata": {}, "outputs": [], "source": "from sklearn.metrics import classification_report, confusion_matrix"}, {"cell_type": "code", "execution_count": 64, "metadata": {"scrolled": true}, "outputs": [{"ename": "ValueError", "evalue": "all the input arrays must have same number of dimensions", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)", "\u001b[0;32m<ipython-input-64-96ed846ba5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[1;32m   1444\u001b[0m                                                   \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                                                   \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m                                                   sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0mrow_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu'{:>{width}s} '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mu' {:>9.{digits}f}'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mu' {:>9}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mn_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         labels = np.hstack([labels, np.setdiff1d(present_labels, labels,\n\u001b[0;32m-> 1053\u001b[0;31m                                                  assume_unique=True)])\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/conda/anaconda/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"]}], "source": "print(classification_report(y_true, y_pred))"}, {"cell_type": "code", "execution_count": 65, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "[[498  51]\n [ 92 250]]\n"}], "source": "print(confusion_matrix(y_true, y_pred))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.10"}}, "nbformat": 4, "nbformat_minor": 2}